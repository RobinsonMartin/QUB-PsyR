<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.258">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>QUB-PsyR - The Ananlysis of Variance</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./images/QUBlogoWsmall.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">QUB-PsyR</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-intro" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Intro</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-intro">    
        <li>
    <a class="dropdown-item" href="./intro1.html">
 <span class="dropdown-text">R and RStudio</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro2.html">
 <span class="dropdown-text">Running Code in R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro3.html">
 <span class="dropdown-text">Objects and Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro4.html">
 <span class="dropdown-text">Data Frames and Lists</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro5.html">
 <span class="dropdown-text">Saving and Loading Data</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-working-with-r-objects" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Working with R Objects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-working-with-r-objects">    
        <li>
    <a class="dropdown-item" href="./working1.html">
 <span class="dropdown-text">Binary Operators</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working2.html">
 <span class="dropdown-text">Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working3.html">
 <span class="dropdown-text">Numerical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working4.html">
 <span class="dropdown-text">Logical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working5.html">
 <span class="dropdown-text">R Packages</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistical-inference" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Statistical Inference</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-statistical-inference">    
        <li>
    <a class="dropdown-item" href="./inference0.html">
 <span class="dropdown-text">A Primer on Statistical Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference1.html">
 <span class="dropdown-text">The t-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference2.html">
 <span class="dropdown-text">The ChiÂ²-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference3.html">
 <span class="dropdown-text">Correlations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference4.html">
 <span class="dropdown-text">Analysis of Variance</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The Ananlysis of Variance</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The Analysis of Variance (ANOVA) is a generalisation of the <span class="math inline">\(t\)</span>-Test. It is used to test the difference between two or more means against zero. When comparing groups using ANOVA, we partition the total variance inherent to the data (collapsed across all groups) into the variance between groups (i.e., the variance of the group means) and the variance within groups.</p>
<section id="the-foundations-of-anova" class="level2">
<h2 class="anchored" data-anchor-id="the-foundations-of-anova">The foundations of ANOVA</h2>
<p>A key concept in ANOVA is that of the <strong>sum of squares</strong>. To understand the sum of squares, let us consider the formal definition of the variance <span class="math inline">\(\sigma^2\)</span> of a variable, which looks as follows:</p>
<p><span class="math display">\[\sigma^2_x = \frac{1}{n} \times \underbrace{\Sigma{(x_i - \bar{x})^2}}_\text{sum of squares}\]</span></p>
<p>From this equation, we can see that the variance of the variable <span class="math inline">\(x\)</span> is the product of two components. One is the <strong>sum of squares</strong>, that is, the sum of the squared deviations of each observation <span class="math inline">\(x_i\)</span> from their mean <span class="math inline">\(\bar{x\)</span>}. The second factor simply divides this sum of squares by the number of observations <span class="math inline">\(n\)</span>.</p>
<p>When we estimate the true variance <span class="math inline">\(\sigma^2_x\)</span> from data we collected, using the formula above produces a slight bias. Specifically, our estimate of the true variance will be systematically too low. To arrive at an unbiased estimate, we need to divide the um of squares by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>, leading to the following formal definition of the <strong>estimate of the variance</strong> <span class="math inline">\(\hat{\sigma}^2_x\)</span>:</p>
<p><span class="math display">\[\hat{\sigma}^2_x = \frac{1}{n-1}\Sigma{(x_i - \bar{x})^2}\]</span></p>
<div class="alert alert-success">
<p><strong>Fun fact</strong>: Dividing a sum of squares by its degrees of freedom yields the so called <strong>mean squares</strong>. The mean squares follow a <span class="math inline">\(\chi^2\)</span>-distribution with the respective degrees of freedom.</p>
</div>
</section>
<section id="the-logic-of-the-anova" class="level2">
<h2 class="anchored" data-anchor-id="the-logic-of-the-anova">The logic of the ANOVA</h2>
<p>The whole idea of ANOVA rests on the fact that the variance can be partitioned into the the sum of its parts. This is also true for the the <strong>sum of squares</strong>. As a very basic rule, we can state that:</p>
<p><span class="math display">\[SS_{total} = SS_{between} + SS_{within}\]</span></p>
<p>Here, <span class="math inline">\(SS_{total}\)</span> is a measure of the total variability of a variable, <span class="math inline">\(SS_{between}\)</span> represents that part of the total variability that is due to differences of the group means, and <span class="math inline">\(SS_{within}\)</span> represents the part of the total variability that results from heterogeneity within the groups.</p>
<p>Similar to the <span class="math inline">\(t\)</span>-test, ANOVA is a signal to noise ratio, where we treat variability between groups as the signal and variability within groups as the noise. The test statistic we use to test for significant mean differences between groups is the <span class="math inline">\(F\)</span>-value, which is formally defined as:</p>
<p><span class="math display">\[F = \frac{VAR_{between}}{VAR_{within}}=\frac{\frac{SS_{between}}{df_{between}}}{\frac{SS_{within}}{df_{within}}} = \frac{MS_{between}}{MS_{within}}\]</span></p>
<p>In the formula above, <span class="math inline">\(MS\)</span> is the corresponding <em>mean squares</em>.</p>
<div class="alert alert-success">
<p><strong>Fun fact</strong>: Based on the formula above, we can easily derive that <span class="math inline">\(F\)</span> is the ratio of two <span class="math inline">\(\chi^2\)</span>-distributed variables. Both the numerator and the denominator constitute a sum of squares divided by its degrees of freedom. That is also the reason why the <span class="math inline">\(F\)</span>-distribution has two degrees of freedom, one for the numerator and one for the denominator.</p>
</div>
<p>How we compute the mean squares depends on the type of ANOVA we run and the number of groups we compare in it.</p>
<p>However, we can state generally how we compute the different <strong>sum of squares</strong>. First of all, letâs remember how we compute the total sum of squares, <span class="math inline">\(SS_{total}\)</span>:</p>
<p><span class="math display">\[SS_{total} = \sum_{i=1}^{N} (x_i - \bar{x})^2\]</span></p>
<p>The total sum of squares represent the sum of the squared deviation of all <span class="math inline">\(N\)</span> observed data points from the grand mean <span class="math inline">\(\bar{x}\)</span>. Now lets look at the formula for <span class="math inline">\(SS_{between}\)</span>.</p>
<p><span class="math display">\[SS_{between} = \sum_{j=1}^{J} n_j \times (\bar{x_j} - \bar{x})^2\]</span> Here, <span class="math inline">\(J\)</span> is the number of groups we compare, and <span class="math inline">\(n_j\)</span> is the sample size of group <span class="math inline">\(j\)</span>. For the <span class="math inline">\(SS_{between}\)</span> we pretend that there is no variance within the <span class="math inline">\(J\)</span> groups at all. Each observation is represented by its groupâs mean <span class="math inline">\(\bar{x_j}\)</span>, and we compute the variability as the difference of these group means from the grand mean <span class="math inline">\(\bar{x}\)</span>. Therefore, the <span class="math inline">\(SS_{between}\)</span> isolates the between-group part of the total variability of <span class="math inline">\(x\)</span>. Letâs now turn to the <span class="math inline">\(SS_{within}\)</span>.</p>
<p><span class="math display">\[SS_{within} = \sum_{j=1}^{J} \sum_{k = 1}^{n_j} (x_{jk} - \bar{x_j})\]</span> Again, <span class="math inline">\(J\)</span> is the number of groups we compare, and <span class="math inline">\(n_j\)</span> is the sample size in group <span class="math inline">\(j\)</span>. The <span class="math inline">\(x_{jk}\)</span> refers to the <span class="math inline">\(k\)</span>th observation in group <span class="math inline">\(j\)</span>. For the <span class="math inline">\(SS_{within}\)</span>, we pretend that there is no variance between groups at all. We do so by substituting the <em>grand mean</em> for the respective group means <span class="math inline">\(\bar{x_j}\)</span>. Thus, the <span class="math inline">\(SS_within\)</span> isolates the within-group variability of <span class="math inline">\(x\)</span>.</p>
<p>The final thing we need to understand before we can delve into the actual ANOVAs is the <span class="math inline">\(F\)</span>-statistic. As we have seen above, we compute <span class="math inline">\(F\)</span> as a ratio of the <span class="math inline">\(MS_{between}\)</span> and the <span class="math inline">\(MS_{within}\)</span>. This ratio is interesting in several ways:</p>
<ol type="1">
<li>Since the <span class="math inline">\(SS_{between}\)</span> usually has much fewer degrees of freedom than that <span class="math inline">\(SS_{within}\)</span>, the variability between groups does not have to be nearly as large as the variability within groups to produce a large <span class="math inline">\(F\)</span>-value.</li>
<li>The more groups we compare, the lower the <span class="math inline">\(F\)</span>-ratio will be, ceteris paribus. However, this does not necessarily mean that it becomes more difficult to detect significant mean differences. The more groups we compare, and the more numerator degrees of freedom our test has, the lower the critical <span class="math inline">\(F\)</span>-value past which we consider a result statistically significant.</li>
<li>The larger our total sample, the more denominator degrees of freedom we have, and smaller the noise becomes in our signal-to-noise ratio, ceteris paribus. This makes intuitive sense: as the samples size increases, our measurement becomes more precise, making it easier to detect differences between group means.</li>
</ol>
<div class="alert alert-success">
<p><strong>Fun fact</strong>: If we use an ANOVA to compare two means, we effectively run a <span class="math inline">\(t\)</span>-test but discard its ability to indicate the direction of the effect.</p>
<p>In such cases <span class="math inline">\(F = t^2\)</span>, and the <span class="math inline">\(p\)</span>-value of both tests will be identical if we run a <span class="math inline">\(t\)</span>-test assuming equal variances.</p>
</div>
<p>ANOVAs come in various flavours. In the following, we will look at some of them, namely:</p>
<ul>
<li>one-factorial ANOVAs (between-subjects)</li>
<li>two-factorial ANOVAs (between-subjects)</li>
<li>repeated-measures ANOVAs (within-subjects)</li>
<li>mixed ANOVAs (at least one between and within factor)</li>
</ul>
</section>
<section id="one-factorial-anova" class="level2">
<h2 class="anchored" data-anchor-id="one-factorial-anova">One-factorial ANOVA</h2>
<p>In a one-factorial ANOVA, we compare two or more group means such that we consider each group to represent one level of the same grouping variable or factor. The Null hypothesis is that all group means are equal, and the alternative hypothesis is that not all group means are equal.</p>
<p>Running ANOVAs in base R tends to be very clunky because R is more centered around classic regression models. Therefore, we wonât be using base R to run ANOVAs, but instead use an R package called <em>afex</em> (Analysis of Factorial Experiment). That means, we need to install and load <em>afex</em> first.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("afex")</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(afex)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
<p>Once we have done that, we can start doing ANOVAs with one of several functions:</p>
<ul>
<li><em>aov_car</em></li>
<li><em>aov_4</em></li>
<li><em>aov_ez</em></li>
</ul>
<p>The three functions serve the same goal and do the same things, but they differ in terms of the syntax. The function <em>aov_car</em> uses syntax that is most closely related the the (clunky) base R version of ANOVA. In contrast, <em>aov_4</em> uses syntax based on the popular <em>lme4</em> package that is widely used for the analysis of generalised mixed models. Thus, this function is ideally suited for users who are already familiar with <em>lme4</em>. Finally, <em>aov_ez</em> uses a completely string-based format, that is, it does not require a formula type object as a function argument. The advantage of <em>aov_ez</em> is that it is very convenient and easy to handle (thus the suffix âezâ). This comes at the cost of flexibility. The lack of a formula means that we are stuck with a full ANOVA model. The other two functions technically allow us to specify models that omit certain main effects or interactions. However, since we will rarely want to run these incomplete models, this is a drawback that usually causes no hassles. In the following, we will focus on the <em>aov_ez</em> function and leave exploration of the other functions to the discretion of the reader,</p>
<p>Here are the most important function arguments of <em>aov_ez</em>:</p>
<ul>
<li><em>id</em> (necessary): a character value indicating the name of the variable that contains our subject ID</li>
<li><em>dv</em> (required): another character value; the name of the variable containing the data the group means of which we want to compare</li>
<li><em>data</em> (required): an R object of type data frame containing the data we want to analyse</li>
<li><em>between</em> (optional): a character string or character vector indicating the name(s) of the variable(s) constituting the between-subjects factor(s) of our design; default is NULL meaning that there are no between-subjects factors</li>
<li><em>within</em> (optional): a character string or character vector indicating the name(s) of the variable(s) constituting the within-subjects factor(s) of our design; default is NULL meaning that there are no within-subjects factors</li>
<li>covariate: a character value or vector indicating the name(s) of the covariate(s) in our analysis</li>
<li>factorize (optional): a logical value; determines if the between- and within-subject variables are turned into factors prior to the analysis; default is TRUE; if our design has at least one covariate, we need to set this to FALSE and make sure that all factors are defined as such manually</li>
<li><em>anova_table</em> (optional): a list of further arguments passed to the function; the ones we may be interested in are <em>es</em> (effect size; default is âgesâ, which yields <span class="math inline">\(\eta^2\)</span> as an effect size measure, but we can switch it to ânoneâ or to âpesâ, which yields <span class="math inline">\(\eta^2_p\)</span>) and <em>correction</em> (non-sphericity correction method; default is ânoneâ, bu we can switch it to âGGâ for the Greenhouse-Geisser or âHFâ for the Huynh-Feldt correction)</li>
</ul>
<p>For the purpose of running a one-factorial between-subjects ANOVA, we can disregard some of the function arguments shown above. The only ones we need are <em>id</em>, <em>dv</em>, <em>between</em>, and possibly <em>anova_table</em> in case we want to obtain the effect size.</p>
<div class="alert alert-danger">
<p>Now that we want to do ANOVAs, it is time to talk about <strong>factors</strong>. In R, <strong>factors</strong> are a special type of vector that contain both values and labels for those values. The different values of vectors are considered to be categories. Factors are important because the ANOVA-function we use here requires its between- and within-subject variables to be factors.</p>
<p>We can create a factor using the <em>factor</em> function by feeding it the following function arguments:</p>
<ul>
<li><em>x</em>: a vector we want to turn into a factor</li>
<li><em>levels</em>: a vector containing all possible values the factor can take</li>
<li><em>labels</em>: a character vector assigning a label to each level of the factor</li>
</ul>
</div>
<p>Lets look at an example, in which we test whether the means of three groups are equal or not. First, we need to create some data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a data frame containing data from 30 subjects in three groups of 10 each; here, "id" is the subject identifier, "cond" is the between-subjects grouping variable, and "dv" contains the outcome variable we want to compare between groups</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>my_df <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># subject ID</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">ID =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>,      </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># between-subjects-factor 'cond'</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">cond =</span> <span class="fu">factor</span>(  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rep</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">each =</span> <span class="dv">10</span>),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">levels =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">'control'</span>, <span class="st">'treatment1'</span>, <span class="st">'treatment2'</span>)),</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># outcome variable 'dv'</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">dv =</span> <span class="fu">c</span>(</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">12</span>,  <span class="dv">9</span>, <span class="dv">14</span>, <span class="dv">11</span>, <span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">18</span>, <span class="dv">12</span>), <span class="co"># dv data for control</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>( <span class="dv">9</span>,  <span class="dv">7</span>, <span class="dv">15</span>, <span class="dv">14</span>,  <span class="dv">8</span>,  <span class="dv">7</span>, <span class="dv">16</span>, <span class="dv">13</span>, <span class="dv">11</span>, <span class="dv">16</span>), <span class="co"># dv data for treatment1</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="dv">12</span>, <span class="dv">11</span>, <span class="dv">11</span>,  <span class="dv">9</span>,  <span class="dv">8</span>, <span class="dv">13</span>,  <span class="dv">8</span>,  <span class="dv">6</span>, <span class="dv">14</span>,  <span class="dv">7</span>)) <span class="co"># dv data for treatment2</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can inspect how the data frame looks using the <em>head</em> function.</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  ID    cond dv
1  1 control 10
2  2 control 12
3  3 control  9
4  4 control 14
5  5 control 11
6  6 control 15</code></pre>
</div>
</div>
</div>
<p>Now that we have some data, we can run the ANOVA. The syntax looks as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aov_ez</span>(<span class="at">id =</span> <span class="st">'ID'</span>, <span class="at">between =</span> <span class="st">'cond'</span>, <span class="at">dv =</span> <span class="st">'dv'</span>, <span class="at">data =</span> my_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is what the output in the cosole looks like:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Contrasts set to contr.sum for the following variables: cond</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: dv
  Effect    df  MSE    F  ges p.value
1   cond 2, 27 9.27 2.44 .153    .106
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</code></pre>
</div>
</div>
</div>
<p>As we can see, R displays an ANOVA table in the console along with some additional information. The output is preceded by a message (this is NOT an error message; the code ran properly). This message informs us that the <em>aov_ez</em> function set the contrast type for our factor âcondâ to âcontr.sumâ. What this means is that the contrast underling our factor was forced into effect coding because that is the format that ANOVAs use. We donât need to concern ourselves with that.</p>
<p>Next, R will tell us that this output is an ANOVA table based on type-3 sum of squares. Type-3 sums of squares are what most statistics packages use. If your knowledge of statistics is so advanced that you can make an informed decision that you would prefer type-2 sums of squares, you can change it by setting the <em>type</em> function argument to 2.</p>
<p>Now for the important bits. R shows us what the response variable in our model is, namely âdvâ. Below that information, it displays the ANOVA table. Because we ran a one-factorial ANOVA; this table contains only one row. Here, we can see the name of the between-subjects factor (<em>effect</em>), the numerator and denominator degrees of freedom for its <span class="math inline">\(F\)</span>-value (<em>df</em>), the mean squares of the effect (<em>MSE</em>), the <span class="math inline">\(F\)</span>-value, the generalised <span class="math inline">\(\eta^2\)</span> as a measure of the effect size, and the <span class="math inline">\(p\)</span>-value.</p>
<p>In our example, the mean difference is not statistically significant, which mans that we cannot reject the null hypothesis. In other words, we cannot say whether the true means between the three groups differ.</p>
<div class="alert alert-info">
<p>Similar to the <span class="math inline">\(\chi^2\)</span>-test, the <span class="math inline">\(F\)</span>-test we use in an ANOVA is always a one-tailed test because it is based on squared variables. Therefore, the test has no âdirectionâ as a <span class="math inline">\(t\)</span>-test would.</p>
<p>Why is this important? Sometimes, we might encounter a scientific article, in which the authors state that they ran a âone-tailedâ ANOVA test, but what they do in those articles is simply the divide their <span class="math inline">\(p\)</span>-value by 2. This practice (often encountered when the regular <span class="math inline">\(p\)</span>-value lies between .05 and .10) rests on the erroneous belief that all statistical tests are - per default - two-tailed and can, therefore, also be run as a one-tailed test with slightly greater power.</p>
</div>
</section>
<section id="disentangling-significant-effects-in-anovas" class="level2">
<h2 class="anchored" data-anchor-id="disentangling-significant-effects-in-anovas">Disentangling significant effects in ANOVAs</h2>
<p>In the example above, we had to retain the Null hypothesis because the analysis did not show evidence that the three means were different from each other. In those cases, there is no need for further analyses. However, things look a bit different when the ANOVA yields a significant result. Letâs look at an example.</p>
<p>In this example, we will compare two treatments and one control condition with data for 30 participants in each condition. The data is stored in a data frame called <em>my_df2</em>. Here is what the data looks like (we use the function <em>head</em> on the data frame to have R show us the first 6 lines).</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  ID    cond  dv
1  1 control  88
2  2  treat1 119
3  3  treat2 119
4  4 control 103
5  5  treat1 103
6  6  treat2 137</code></pre>
</div>
</div>
</div>
<p>We now run the ANOVA on the data. Other than before, we will define the result of the analysis as a new R object. This will make it easier for us to disentangle the effect later on. Here is the syntax:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run a one-factorial ANOVA and save its results as a new R object</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">=</span> <span class="fu">aov_ez</span>(<span class="at">id =</span> <span class="st">'ID'</span>, <span class="at">dv =</span> <span class="st">'dv'</span>, <span class="at">between =</span> <span class="st">'cond'</span>, <span class="at">data =</span> my_df2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will now see a new object called âmodel1â in the <strong>Environment</strong>. R will tell us that this object is a list. Entering the new objectâs name as syntax will show us the result of the ANOVA just as if we had called the function as is instead of defining it as a new object. Here is the console output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Anova Table (Type 3 tests)

Response: dv
  Effect    df   MSE         F  ges p.value
1   cond 2, 87 89.48 22.91 *** .345   &lt;.001
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</code></pre>
</div>
</div>
</div>
<p>As we can see, the effect of <em>cond</em> (the grouping variable in our fictional data) is statistically significant. We can now state - with the usual confidence - that the means of the three groups are not equal. However, we cannot say anything else. Since an ANOVA uses the squared test statistic <span class="math inline">\(F\)</span>, we have no information on the direction of the mean differences, nor do we know which means differ. Thus, we need further analyses to get a clear picture of the mean differences the ANOVA detected.</p>
<div class="alert alert-info">
<p>As a useful - if somewhat brutish - metaphor, think of an ANOVA as firing a shotgun into think fog. A statistically significant effect means that we hit something, but we do not know what we hit. In order to find that out we need to venture into the fog and have a closer look.</p>
<p>(Credit for this metaphor goes to Prof.&nbsp;Dieter Heyer)</p>
</div>
<p>In order to disentangle a significant effect in an ANOVA with three or more groups, we need to run <strong>post-hoc</strong> analyses. There are many different ways to run such post-hoc analyses. We will look at three of them here:</p>
<section id="post-hoc-t-tests" class="level3">
<h3 class="anchored" data-anchor-id="post-hoc-t-tests">Post-hoc t-tests</h3>
<p>Perhaps the easiest way to disentangle significant effects in an ANOVA is running <span class="math inline">\(t\)</span>-tests to compare the means of the groups. We already know how to do this, namely by using the <em>t.test</em> function. The advantage, beyond the fact that it is easy, is that we can specify one-tailed <span class="math inline">\(t\)</span>-tests if they are theoretically justified and, ideally, preregistered as follow-up tests in case an ANOVA yields a significant result.</p>
<p>In our specific example, letâs assume that we expected both treatments to be effective, which should manifest in higher mean scores as compare with the control condition. Let us further assume that we had no specific prediction regarding the relative effectiveness of the two treatments. In this case, we would run two one-tailed <span class="math inline">\(t\)</span>-tests, one comparing the first treatment condition with the control condition, and another comparing the second treatment with the control condition. For the final post-hoc comparison, we would run a two-tailed <span class="math inline">\(t\)</span>-test comparing the two treatment conditions.</p>
<p>Lets have a look at the syntax first. It could look like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># one-tailed t-test, testing whether dv scores are higher in the first treatment condition than in the control condition</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> my_df2<span class="sc">$</span>dv[my_df2<span class="sc">$</span>cond <span class="sc">==</span> <span class="st">'treat1'</span>],</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> my_df2<span class="sc">$</span>dv[my_df2<span class="sc">$</span>cond <span class="sc">==</span> <span class="st">'control'</span>],</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">alternative =</span> <span class="st">'greater'</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># one-tailed t-test, testing whether dv scores are higher in the second treatment condition than in the control condition</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> my_df2<span class="sc">$</span>dv[my_df2<span class="sc">$</span>cond <span class="sc">==</span> <span class="st">'treat2'</span>],</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> my_df2<span class="sc">$</span>dv[my_df2<span class="sc">$</span>cond <span class="sc">==</span> <span class="st">'control'</span>],</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">alternative =</span> <span class="st">'greater'</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># two-tailed t-test, testing whether dv scores differ between the two treatments</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> my_df2<span class="sc">$</span>dv[my_df2<span class="sc">$</span>cond <span class="sc">==</span> <span class="st">'treat1'</span>],</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> my_df2<span class="sc">$</span>dv[my_df2<span class="sc">$</span>cond <span class="sc">==</span> <span class="st">'treat2'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is what R outputs in the console once we run the three tests:</p>
<p>:::[.alert .alert-warning]</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
    Welch Two Sample t-test

data:  my_df2$dv[my_df2$cond == "treat1"] and my_df2$dv[my_df2$cond == "control"]
t = 2.1864, df = 57.789, p-value = 0.01642
alternative hypothesis: true difference in means is greater than 0
95 percent confidence interval:
 1.232097      Inf
sample estimates:
mean of x mean of y 
102.36667  97.13333 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Welch Two Sample t-test

data:  my_df2$dv[my_df2$cond == "treat2"] and my_df2$dv[my_df2$cond == "control"]
t = 6.6635, df = 57.541, p-value = 5.552e-09
alternative hypothesis: true difference in means is greater than 0
95 percent confidence interval:
 12.13568      Inf
sample estimates:
mean of x mean of y 
113.33333  97.13333 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Welch Two Sample t-test

data:  my_df2$dv[my_df2$cond == "treat1"] and my_df2$dv[my_df2$cond == "treat2"]
t = -4.3842, df = 57.951, p-value = 4.968e-05
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -15.973871  -5.959462
sample estimates:
mean of x mean of y 
 102.3667  113.3333 </code></pre>
</div>
</div>
<p>:::</p>
<p>As we can see, all three tests show evidence of mean differences. That is, based on these post-hoc comparisons, we can now say why the ANOVA yielded a significant effect: all three means differ from each other.</p>
<p>But wait! Donât we need to correct for multiple comparisons? The answer is: it depends on your testing philosophy. If you want to treat the complete post-hoc analysis as a single analysis, then yes, you need to control your type-I error. The easiest way to do this is to use Bonferroniâs correction, that is, we divide the tolerated type-I error level <span class="math inline">\(\alpha\)</span> by the number of tests we ran <span class="math inline">\(k\)</span>.</p>
<p>In our case, this means dividing the usual <span class="math inline">\(\alpha\)</span> level of .05 by three (the number of post-hoc tests we ran). We now consider a post-hoc <span class="math inline">\(t\)</span>-test significant only if the associated <span class="math inline">\(p\)</span>-value is smaller than .01667. In our example, correcting for multiple testing does not change the general pattern of results. All three tests still yield significant mean differences.</p>
<div class="alert alert-danger">
<p>In this example, things would look differently, had we used two-tailed tests to compare the treatments with the control condition. Specifically, the comparison of the first treatment condition with the control condition would have yielded a significant result when not correcting for multiple comparisons (the tests then yields a <span class="math inline">\(p\)</span>-value of .033).</p>
<p>After using a Bonferroni correction, this comparison would no longer be statistically significant since the <span class="math inline">\(p\)</span>-value of the two-tailed tests exceeds the adjusted <span class="math inline">\(\alpha\)</span>-level of .01667.</p>
</div>
</section>
<section id="tukeys-method-for-pairwise-comparisons" class="level3">
<h3 class="anchored" data-anchor-id="tukeys-method-for-pairwise-comparisons">Tukeyâs method for pairwise comparisons</h3>
<p>Running pairwise comparisons using <span class="math inline">\(t\)</span>-tests is fine if we compare only few groups. However, as the number of groups we compare in an ANOVA increases, so does the number of possible pairwise comparisons. In fact, the number of comparisons is <span class="math inline">\((k^2-k)/2\)</span>, that is, it grows exponentially.</p>
<p>An alternative to running individual tests is Tukeyâs method, also known as Tukeyâs honestly significant difference (HSD). In technical terms, HSD computes the critical mean difference for which a pairwise comparison is considered significant, and then judges each comparison by that difference. The test statistic <span class="math inline">\(q\)</span> follows the Studentised range distribution, the shape of which depends on the number of groups <span class="math inline">\(k\)</span> and the sample size <span class="math inline">\(n\)</span> (via the distributionâs degrees of freedom). Because the distribution of the <span class="math inline">\(q\)</span>-statistic considers the number of groups, the HSD adjusts for multiple comparisons.</p>
<p>If we want to run post-hoc comparisons using HSD in R, we need another package called <em>emmeans</em>. This package contains two functions we need: <em>emmeans</em> (yes, it has the same name as the package) and <em>contrast</em>.</p>
<p>Letâs first look at the <em>emmeans</em> function. When we call this function, we need to specify two function arguments. The first is called <em>object</em>. Here, we need to feed the function an R object containing the results of an ANOVA (good thing we saved our ANOVA as an R object). Second, we need to tell the function the name of grouping variable in our data. We do so by defining the function argument <em>spec</em> as a character string equalling the name of the respective variable (in our example, the grouping variable is âcondâ).</p>
<p>The second function, <em>contrast</em> also needs two function arguments to do what we want it to do. The first is, again, called <em>object</em>. However, the <em>contrast</em> function does not need an ANOVA type object. Instead, it needs the type of object that the <em>emmeans</em> function returns (it is called an âemmGridâ type object). As a second argument, we need to specify <em>method</em>, which determines the type of post-hoc comparisons the function computes. The default is âeffâ, which tests each group against the mean of all groups, but this is not what we want R to do. In order to get the HSD comparisons, we need to set this argument to âtukeyâ.</p>
<p>Letâs have a look at the code using the ANOVA model we saved as an R object above (âmodel1â). There are two ways of writing this code, one that creates a separate object of type âemmGridâ in the environment which we can feed to the <em>contrast</em> function, and another that omits creating this object by feeding the <em>contrast</em> function another function call as its <em>object</em> (the latter may be preferable because we wonât do much with an âemmGridâ type object).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># uncomment to install the package emmeans</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(emmeans)</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load the library emmeans</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Alternative 1: save the emmGrid object separately</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># create an emmGrid object from the ANOVA</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>grid1 <span class="ot">=</span> <span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co"># obtain Tukey's HSD using the function "contrast"</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(<span class="at">object =</span> grid1, <span class="at">method =</span> <span class="st">'tukey'</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="do">## Alternative 2: don't create an emmGrid object</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co"># obtain Tukey's HSD using the function "contrast"</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(<span class="at">object =</span> <span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>), </span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">method =</span> <span class="st">'tukey'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Running either version of the code, will produce the following output in the console:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> contrast         estimate   SE df t.ratio p.value
 control - treat1    -5.23 2.44 87  -2.143  0.0872
 control - treat2   -16.20 2.44 87  -6.633  &lt;.0001
 treat1 - treat2    -10.97 2.44 87  -4.490  0.0001

P value adjustment: tukey method for comparing a family of 3 estimates </code></pre>
</div>
</div>
</div>
<p>As we can see, the output is a table that contains the result of the HSD post-hoc test. Here, R will tell us which groups were compared and what the estimated mean difference for the respective comparison is. It will also tell us the standard error of the mean differences and the degrees of freedom (total sample size <span class="math inline">\(n\)</span> minus the number of groups <span class="math inline">\(k\)</span>). Finally, there will be a <span class="math inline">\(t\)</span>-value and and <span class="math inline">\(p\)</span>-value for each of the pairwise comparisons.</p>
<p>Based on the HSD post-hoc tests, we would conclude that scores are higher in treatment 2 than in both the control condition and treatment 1, but we cannot say whether scores in treatment 1 are different from those in the control condition.</p>
</section>
<section id="custom-post-hoc-contrasts" class="level3">
<h3 class="anchored" data-anchor-id="custom-post-hoc-contrasts">Custom post-hoc contrasts</h3>
<p>The third way to run post-hoc tests we will consider here is to run custom <span class="math inline">\(t\)</span>-contrasts. What this means is that we define ourselves how we want to compare the group means in case of a significant effect in the ANOVA. When using custom contrasts, we can choose how many comparisons we run, which means we want to compare, and how to compare them.</p>
<p>What we are effectively doing here is to compute weighted means of our conditions such that the weights adds to zero. For example, we could compare two group means (just as we did with the two previously described methods), but we could also test whether two groups differ from a third.</p>
<p>Let us go back to our ANOVA example and assume that we want to run two post-hoc tests. The first tests whether having any treatment leads to different scores than being in the control condition. The second tests whether the effectiveness of the two treatments differs. Here is what the two contrasts would look like:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>control</th>
<th>treatment 1</th>
<th>treatment 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>contrast 1</td>
<td>-1</td>
<td>+0.5</td>
<td>+0.5</td>
</tr>
<tr class="even">
<td>contrast 2</td>
<td>0</td>
<td>1</td>
<td>-1</td>
</tr>
</tbody>
</table>
<p>Letâs dissect that! For contrast 1, we compare the control group with the mean of the two treatment groups. In contrast 2, we compare only the two treatment groups; the 0 weight for the control condition means that its mean does not play any role in this contrast.</p>
<div class="alert alert-success">
<p>In a design with three or more groups, contrasts comparing two group means have a distinct advantage over run-of-the-mill <span class="math inline">\(t\)</span>-tests that compare the same means.</p>
<p>The reason is that - assuming equal variances in all groups - information from any group can be used to estimate the variance of the mean difference. While the group means of those conditions that receive a contrast weight of zero play no role in determining the signal, we can use the data from these groups to reduce the noise in our test.</p>
<p>Therefore, a <span class="math inline">\(t\)</span>-contrast will usually be more powerful than a regular <span class="math inline">\(t\)</span>-test, although this advantage decreases with the sample size.</p>
</div>
<p>How do we tell R that we want to run custom contrasts? We can do so using the same <em>contrast</em> function we used to run the HSD test. To run custom contrasts, we simply need to change how we specify the functionâs <em>method</em> argument. To be exact, we need to define this argument as a list in which each element is one contrast.</p>
<p>When defining the list of contrasts, each contrast must be a numeric vector of length <span class="math inline">\(k\)</span>, where <span class="math inline">\(k\)</span> is the number of groups in the grouping variable that we fed into the <em>emmeans</em> function (in our case 3). If we chose the wrong vector length, we will receive an error message. We also need to make sure that the sum of each contrast vector is zero (R will not check this, and the function will work even if we input nonsensical weights). Finally, we can (but do not have to) create these vectors as named elements of the list. Naming the vectors may lead to output that is slightly easer to make sense of.</p>
<p>Here, too, we need to decide whether we save the list of contrasts as a separate object or whether we feed the <em>contrast</em> function a call of the <em>list</em> function (the result will be the same, so it is simply a matter of preference). Now letâs look at the R code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Alternative 1: separate objects</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># create an emmGrid object from the ANOVA</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>grid1 <span class="ot">=</span> <span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># create a list containing the custom contrasts</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>my_contrasts <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">treat_vs_control =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>),</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">treat1_vs_treat2 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># run the custom post-hoc tests using "contrast"</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(<span class="at">object =</span> grid1, <span class="at">method =</span> my_contrasts)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Alternative 2: don't create separate objects</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co"># run the custom post-hoc tests using "contrast"</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(<span class="at">object =</span> <span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>), </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>         <span class="at">method =</span> <span class="fu">list</span>(</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>             <span class="at">treat_vs_control =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>),</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>             <span class="at">treat1_vs_treat2 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>         )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Running either version of the code will prompt R to test the contrasts, and we will receive the following console output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> contrast         estimate   SE df t.ratio p.value
 treat_vs_control     10.7 2.12 87   5.066  &lt;.0001
 treat1_vs_treat2    -11.0 2.44 87  -4.490  &lt;.0001</code></pre>
</div>
</div>
</div>
<p>As we can see, R returns a table with two contrast tests. Since we named the contrasts properly, it is easy to see what these contrasts tested. For each contrast, R will tell is the estimated mean difference, the associated standard error, and the degrees of freedom (<span class="math inline">\(n-k\)</span>, similar to the HSD test described above). It will also show us the <span class="math inline">\(t\)</span>-value and <span class="math inline">\(p\)</span>-value for each contrast. In our example, both contrasts are significant. This means, we can state - with the usual confidence - that the ANOVA was significant because a) getting a treatment leads to higher scores as compared with the control condition, and b) the treatments differ in effectiveness.</p>
<p>But what about multiple comparisons? So far, we have not corrected for multiple comparisons, but we can do so if we want to. The good news is that we do not have to do it manually when using the <em>contrast</em> function. Instead, we can specify a third function argument called <em>adjust</em>. If we use custom contrasts, the default for this argument is ânoneâ, but we can set it to âbonferroniâ (for the classic Bonferroni correction) or âholmâ (for the slightly lees concervative Holm-Bonferroni method) instead. Letâs go with Bonferroni. Here is the code:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-overflow-wrap code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run the custom post-hoc tests using "contrast" and correct</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># for multiple comparisons using Bonferroni's method</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(<span class="at">object =</span> <span class="fu">emmeans</span>(<span class="at">object =</span> model1, <span class="at">specs =</span> <span class="st">'cond'</span>), </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">method =</span> <span class="fu">list</span>(</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">treat_vs_control =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>),</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">treat1_vs_treat2 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>             ),</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">adjust =</span> <span class="st">'bonferroni'</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>         )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now letâs look at the console output:</p>
<div class="alert alert-warning">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> contrast         estimate   SE df t.ratio p.value
 treat_vs_control     10.7 2.12 87   5.066  &lt;.0001
 treat1_vs_treat2    -11.0 2.44 87  -4.490  &lt;.0001

P value adjustment: bonferroni method for 2 tests </code></pre>
</div>
</div>
</div>
<p>As we can see, not much has changed in terms of statistical significance, which makes sense because the unadjusted <span class="math inline">\(p\)</span>-values were already very low. However, R now tells us at the bottom of the table that <span class="math inline">\(p\)</span>-values were adjusted using the Bonferroni method.</p>
<div class="alert alert-info">
<p>Custom contrasts are really useful because of their flexibility. They allow us to test very specific hypotheses. In fact, if we can state in advance which means in our design should differ (for example, because we have a strong theory to base our hypotheses on), we can technically skip the ANOVA altogether and instead run only the contrast tests. In those cases, we speak of a-priori contrasts.</p>
</div>
</section>
<section id="a-concluding-remark-on-post-hoc-comparisons" class="level3">
<h3 class="anchored" data-anchor-id="a-concluding-remark-on-post-hoc-comparisons">A concluding remark on post-hoc comparisons</h3>
<p>We started the journey into post-hoc analyses using the metaphor of the ANOVA as firing a shotgun into thick fog which - in case we hit something - necessitates wandering into the fog in order to find out what exactly we hit. As the examples above show, the answer to that crucial question depends on which post-hoc comparisons we run (pairwise comparisons vs.&nbsp;custom contrasts), the type of alternative hypotheses we test (one-tailed vs.&nbsp;two-tailed tests), and whether and how we control for type-I error inflation due to multiple comparisons.</p>
<p>When trying to disentangle a significant effect in an ANOVA, we may find ourselves faced with multiple options, each of which is valid and can be argued for convincingly. However, even subtle differences between these options may lead to qualitatively different conclusions. The practical advice here is to preregister exactly which tests we will run in case an ANOVA yields a significant result (ideally by providing the R code for the post-hoc analysis).</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>