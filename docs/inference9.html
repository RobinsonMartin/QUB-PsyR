<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>QUB-PsyR - Multi-level models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./images/QUBlogoWsmall.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">QUB-PsyR</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-intro" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Intro</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-intro">    
        <li>
    <a class="dropdown-item" href="./intro1.html">
 <span class="dropdown-text">R and RStudio</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro2.html">
 <span class="dropdown-text">Running Code in R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro3.html">
 <span class="dropdown-text">Objects and Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro4.html">
 <span class="dropdown-text">Data Frames and Lists</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro5.html">
 <span class="dropdown-text">Saving and Loading Data</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-working-with-r-objects" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Working with R Objects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-working-with-r-objects">    
        <li>
    <a class="dropdown-item" href="./working1.html">
 <span class="dropdown-text">Binary Operators</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working2.html">
 <span class="dropdown-text">Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working3.html">
 <span class="dropdown-text">Numerical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working4.html">
 <span class="dropdown-text">Logical Indexing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./working5.html">
 <span class="dropdown-text">R Packages</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistical-inference" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Statistical Inference</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-statistical-inference">    
        <li>
    <a class="dropdown-item" href="./inference0.html">
 <span class="dropdown-text">A Primer on Statistical Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference1.html">
 <span class="dropdown-text">The t-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference2.html">
 <span class="dropdown-text">The Chi²-test</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference3.html">
 <span class="dropdown-text">Correlations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference4.html">
 <span class="dropdown-text">One-factorial Analysis of Variance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference5.html">
 <span class="dropdown-text">Two-factorial Analysis of Variance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference6.html">
 <span class="dropdown-text">Repeated measures and mixed ANOVAs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference7.html">
 <span class="dropdown-text">Simple linear regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference8.html">
 <span class="dropdown-text">Multiple linear regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./inference9.html">
 <span class="dropdown-text">Multi-level models</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Multi-level models</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In the real world (and in some psychological experiments), data is embedded in a hierarchical structure. If we want to apply a regression approach to hierarchical data, we need to consider this structure in our models.</p>
<p>Hierarchical data structures consist of at last two levels at which the observation of a criterion variable of interest is possible. Per convention, we define the most fine-rained level of observation as level 1. Level 1 is the most fine-grained one and, thus, the one with the highest number of observations. At level 2, we can cluster the level 1 data into several distinct groups with group membership defined by level 2 variables. We can then cluster level 2 data into distinct groups at level 3, and so on.</p>
<p>Here are some examples:</p>
<ul>
<li>measurement of performance (criterion) in an experiment in several trials (level 1) per participant (level 2)</li>
<li>average grades (criterion) by pupils (level 1) within classrooms (level 2) within schools (level 3)</li>
<li>experienced stress (criterion) of team members (level 1) in different teams (level 2) in different companies (level 3) in different industries (level 4)</li>
</ul>
<p>One common aspect of those examples is that the criterion is always measured at level 1. For example, a school does not have a grade of its own. Instead, the grades are assigned to students. Likewise, a team in an organisation does not experience stress, the people working in it do. That is not to say that we cannot compute an average school grade or team stress level, but the data we need to compute such scores are always gathered at level 1.</p>
<p>Another common aspect of hierarchical data structure is that we can measure predictor variables at each level. Let’s consider the example ‘experiences stress’ from above:</p>
<ul>
<li><strong>Level 1</strong>: team members’ personality, age, gender, organisational tenure</li>
<li><strong>Level 2</strong>: team size, team tenure, team leader leadership style</li>
<li><strong>Level 3</strong>: company reputation, size, market share</li>
<li><strong>Level 4</strong>: industry-level wage level, work hazards, degree of unionisation</li>
</ul>
<p>We could reasonably postulate hypotheses linking any (or all) of the variables above to the criterion (experienced stress). However, the critical question is how to approach a test of these hypotheses in an appropriate way. The answer is: by using multi-level models.</p>
<p>Multi-level models (also known as hierarchical linear models, mixed effects models, or nested-data models) are regression models that take the hierarchical stricture of the data into account by partitioning the variance of the criterion accordingly. As such, they are not unlike repeated measures and mixed ANOVAs where the variance of the observed variable is partitioned into variance between and variance within participants. In fact, these ANOVAs are special types of multi-level models, which means that multi-level models are a more general and, thus, more flexible method to deal with hierarchical data.</p>
<section id="why-considering-the-data-structrue-is-important" class="level2">
<h2 class="anchored" data-anchor-id="why-considering-the-data-structrue-is-important">Why considering the data structrue is important</h2>
<p>The first question we might ask ourselves is why we should bother considering the data structure in the first place. Why not just aggregate the data and run an ordinary linear regression model using the aggregate scores as the criterion? The answer is twofold.</p>
<p>First, depending on our hypotheses aggregation may not be an option. For example, if we wanted to predict school grades from pupils’ cognitive styles (level 1 predictor), the gender of their teachers (a level 2 predictor) and the type of school (level 3 predictor), aggregating the data at the school level won’t work unless we have very good reason to believe that an aggregation of the predictors works without losing explanatory power.</p>
<p>Second, and more importantly, we may fall pray to the <strong>ecological fallacy</strong>. This fallacy means that we draw incorrect conclusion about lower-level predictor-criterion relations when analysing the data at an aggregate level. To illustrate this fallacy, lets look at an example.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference9_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In the example above, we are predicting a criterion from a predictor variable. As we can see, the correlation between the two variables is positive. Now let’s look at the same data again. This time, we will consider that there are five discount groups in our data.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference9_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We now get a completely different picture. Within each of the five groups, there is a strong <strong>negative</strong> correlation of the predictor and the criterion. In our case, neglecting the data structure implies an effect in the opposite direction of the effects we observe within each group. This extreme form of the ecological fallacy is also known as <strong>Simpson’s Paradox</strong>.</p>
<p>Now, does the fact that we obtain different results when considering instead of neglecting the data structure mean that one of the analyses is true while the other is wrong? Not really. When analysing data across groups (i.e., by neglecting group membership), the correlation we observe is a statistical truth, that is, the relation between predictor and criterion exists. However, when we try to make sense of <em>why</em> it occurs, we need to consider the data structure. Why do we get a positive correlation when, in fact, the relation is negative within each group? The answer is: because the groups differ systematically. In other words, the positive correlation between predictor and criterion is a result of group differences (a level 2 effect), whereas at level 1 the relation is negative.</p>
<p>What the example above should make clear is that considering the hierarchical nature of our data provides us with a clearer picture of how our predictors relate to the criterion of interest. This, in turn, will allow us to draw more appropriate inferences about our data. The question now is: how?</p>
</section>
<section id="the-basics-of-multi-level-modelling" class="level2">
<h2 class="anchored" data-anchor-id="the-basics-of-multi-level-modelling">The basics of multi-level modelling</h2>
<p>The core idea of multi-level modelling is, put very simply, to predict level 1 criteria from predictors at various levels. To this end, the variance of the predictor is partitioned into variance at level 1, variance at level 2, and so on. In order to understand how that works, we first need to understand the difference between <strong>fixed effects</strong> and <strong>random effects</strong>.</p>
<p><strong>Fixed effects</strong> are our model’s predictors. We estimate the strength of their relationship with the criterion as regression weights. As we already know there regression weights indicate how the criterion changes when statistically controlling for the other predictors.</p>
<p><strong>Random effects</strong> are unsystematic (or unexplained) variances. They represent the variability of a parameter assuming a normal distribution. Random effects can be used to model the variability of the criterion but also the variability of fixed effects.</p>
<p>We already know a model containing fixed and random effects, namely the simple linear regression. Let’s recap it basic formula:</p>
<p><span class="math display">\[Y = b_0 + b_1X_1 + \epsilon\]</span> With:</p>
<p><span class="math display">\[\epsilon \sim N(0, \sigma^2)\]</span></p>
<p>Here, the parameters <span class="math inline">\(b_0\)</span> and <span class="math inline">\(_b1\)</span> are fixed effects. They are the basis for our model prediction <span class="math inline">\(\hat{Y}\)</span>. In contrast, the residual <span class="math inline">\(\epslion\)</span> is a random effect. While we compute the difference between our model prediction <span class="math inline">\(\hat{Y}\)</span> and the actual criterion <span class="math inline">\(Y\)</span> for each observation, we summarise the residual <span class="math inline">\(\epsilon\)</span> via a single parameter, namely its variance.</p>
<section id="from-simple-linear-regressionn-to-multi-level-modelling" class="level3">
<h3 class="anchored" data-anchor-id="from-simple-linear-regressionn-to-multi-level-modelling">From simple linear regressionn to multi-level modelling</h3>
<p>Let’s start with the most simple regression model, which we will call a single-level intercept only model.</p>
<p><span class="math display">\[Y_i = b_0 + \epsilon_i\]</span>.</p>
<p>In this model, we have only two effects: one fixed effect, namely the intercept <span class="math inline">\(b_0\)</span>, and one random effect, the residual <span class="math inline">\(\epsilon\)</span>. According,y <span class="math inline">\(Y_i\)</span> represent the level of <span class="math inline">\(Y\)</span> for the <span class="math inline">\(i\)</span>th observation, and <span class="math inline">\(\epsilon_i\)</span> is the specific deviation of the <span class="math inline">\(i\)</span>th observation from the model prediction (i.e., the intercept). The model assumes that all the variance of <span class="math inline">\(Y\)</span> is unsystematic and that the unsystematic differences <span class="math inline">\(\epsilon_i\)</span> originate on level 1 (the only level in this model).</p>
<p>Let’s now assume that we know that there is a variable on a higher level (level 2) that allows grouping our level 1 data. There are two ways to handle such a situation. We could either treat the grouping variable as a categorical fixed effect, modelling its relationship with the criterion via a regression weight in a single-level model. Alternatively, we could treat it as a random effect in a two-level model. In our example, we would include a random effect for the intercept of the model (our sole fixed effect).</p>
<div class="alert alert-info">
<p>The decision whether to model the effects of a grouping variable as a fixed or a random effect depends on what we are interested in. If we want to examine the influence of a certain grouping variable, we usually model it as a fixed effect.</p>
<p>As a rule of thumb, we should model something as a fixed effect if we would sue the same grouping (same variable, same levels) in a replication of our study. This includes, experimental manipulations, studying gender effects, etc.</p>
<p>If,in contrast, the grouping variable itself is a random sample (e.g., a sample of schools or a sample of teams in an organisation), we should model it as a random effect. In such cases, we are no interested in how switching from one category to another affects the criterion. Likewise, we would not insist on studying the exact same groups in a replication, but would instead draw another random sample (e.g.&nbsp;a different set of schools or different teams).</p>
</div>
<p>Let’s now look at the most simple two-level model, which assumes that the intercept of the intercept-only model varies between groups formed by a level 2 grouping variable. Note that we will use a slightly different syntax. In this syntax, we will put the levels at which variables or parameters vary in parentheses. This makes it a little easier to parse the indices of the regression parameters as we will see below. Here is the model equation:</p>
<p><span class="math display">\[Y_{(ij)} = b_{0(j)} + \epsilon_{(ij)}\]</span> Where:</p>
<p><span class="math display">\[b_{0(j)} = c_{0(0)} + u_{0(j)}\]</span> Which means that:</p>
<p><span class="math display">\[ Y_{(ij)} + c_{0(0)} + u_{0(j)} + \epsilon_{(ij)} \]</span> With:</p>
<p><span class="math display">\[u_{0(j)} \sim N(0, \sigma_{u_{0(j)}}^2)\]</span> and <span class="math display">\[\epsilon_{(ij)} \sim N(0, \sigma_{\epsilon_{(ij)}}^2)\]</span></p>
<p>The notation using parentheses in the indices allows us to differentiate two pieces of information for the model parameters: a) the parameter name, that is, which effect they correspond to (e.g., <span class="math inline">\(b_0\)</span> to represent the intercept and <span class="math inline">\(b_1\)</span> the effect of the first predictor) and b) whether that parameter is a constant (indicated by the value 0 in parentheses) or whether it varies randomly, indicated by the letter corresponding to the level at which the parameter varies (e.g., <span class="math inline">\(j\)</span> if the parameter varies randomly at level 2). Accordingly, the index of the parameter <span class="math inline">\(b_{0(j)}\)</span> reveals that it is the model intercept (the parameter <span class="math inline">\(b_0\)</span>), and that it varies between the level-2 units (indicated by the <span class="math inline">\(j\)</span> in parentheses).</p>
<p>In the model <span class="math inline">\(Y_{ij}\)</span> is the criterion value of the <span class="math inline">\(i\)</span>th observation in the <span class="math inline">\(j\)</span>th group. The model intercept <span class="math inline">\(b_{0(j)}\)</span> is split into two components, the mean intercept across all <span class="math inline">\(j\)</span> groups <span class="math inline">\(c_{0(0)}\)</span> (the grand mean, which no longer varies between groups, hence the zero in parentheses), and a random component, the random intercept <span class="math inline">\(u_{0(j)}\)</span>. This random component <span class="math inline">\(u_{0(j)}\)</span> indicates how the intercept of the <span class="math inline">\(j\)</span>th level 2 unit deviates from the fixed intercept <span class="math inline">\(c_{0(0)}\)</span>. However, since we model <span class="math inline">\(u_{0(j)}\)</span> as a random effect, we only estimate its variance.</p>
<p>Let’s now turn to the final parameter, the residual <span class="math inline">\(\epsilon_{(ij)}\)</span>. In this multi-level model, the intercept works a bit differently than in a single-level model. It indicates how the <span class="math inline">\(i\)</span> observations in the <span class="math inline">\(j\)</span>th group differ from that group’s intercept, which we get by adding <span class="math inline">\(c_{0(0)}\)</span> (the fixed intercept) and <span class="math inline">\(u_{0(j)}\)</span> (the <span class="math inline">\(j\)</span>th group’s deviation from the fixed intercept). What this means is that the residual <span class="math inline">\(\epsilon_{(ij)}\)</span> no longer represents the deviations between the model prediction and the actual criterion values, but instead denotes the (unexplained) variance <strong>within each group</strong>.</p>
<p>Let’s look at an example and visualise it to get a better grasp of the differences between the two models. Let’s assume we have data from 9 participants (level 1) nested in three groups (level 2). We have one observation per participant. If we modeled the data with a single-level intercept only model, this is how it would look.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference9_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can see, that the residuals <span class="math inline">\(\epsilon_i\)</span> tell us how each participant’s score deviates from the intercept <span class="math inline">\(b_0\)</span>. now let’s look at the multi-level version of the model.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference9_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>As we can see, we can now construe not only the fixed intercept <span class="math inline">\(c_{0(0)}\)</span> but also individual intercept for each of the three groups, which we denote as <span class="math inline">\(c_{0(j)}\)</span>. The residual <span class="math inline">\(\epsilon_{(ij)}\)</span> now tells us how a participant’s score deviates from the intercept of that participant’s group.</p>
<p>The crucial difference between the two models is that single-level model only tells us <em>that</em> there is unexplained variance in the criterion, whereas the multi-level model also tells us at which level this unexplained variance originates.</p>
<p>A multi-level model containing only a fixed and a random intercept (as the one in our example) is also known as the <strong>variance component model</strong>. By comparing the two random effects, we can infer which proportion of the variance of <span class="math inline">\(Y\)</span> originates between versus within the level 2 groups. We can do so by computing the <strong>intra-class correlation</strong> (ICC).</p>
<p><span class="math display">\[ICC = \frac{\sigma_{u_{0(j)}}^2} {\sigma_{u_{0(j)}}^2 + \sigma_{\epsilon_{ij}}^2}\]</span> The larger the variance between groups, indicated by the variance of the random intercept <span class="math inline">\(\sigma_{u_{0(j)}}^2\)</span>, the larger the ICC. Thus, a larger ICC means that values within groups are more similar, which means they are more highly correlated.</p>
</section>
<section id="multi-level-models-with-random-intercepts-and-fixed-slopes" class="level3">
<h3 class="anchored" data-anchor-id="multi-level-models-with-random-intercepts-and-fixed-slopes">Multi-level models with random intercepts (and fixed slopes)</h3>
<p>The variance component model is usually not very interesting because it contains no predictors. In a multi-level model, we can add predictors at each level. We will, for now, only focus on fixed slopes of level-1 variables. As a general rule, a fixed effect in a multi-level model will reduce the unexplained variance at its level. That is, a level 1 fixed effect will explain some of the residual variance, whereas a fixed effect at level 2 will explain some of the variance captured in the random intercept (in a sense we make some of the variability of the intercepts systematic by adding level 2 fixed effects).</p>
<p>Let’s look at the model syntax for a two-level model containing a fixed slope for a level-1 predictor.</p>
<p><span class="math display">\[Y_{(ij)} = b_{0(j)} + b_{1(0)}X_{(ij)} + \epsilon_{(ij)}\]</span> With:</p>
<p><span class="math display">\[b_{0(j)} = c_{0(0)} + u_{0(j)}\]</span> Yielding:</p>
<p><span class="math display">\[Y_{(ij)} = c_{0(0)} + u_{0(j)} + b_{1(0)}X_{1(ij)} + \epsilon_{(ij)}\]</span></p>
<p>Let’s try to make sense of the notation. Again, <span class="math inline">\(Y_{(ij)}\)</span> is the criterion value of the <span class="math inline">\(i\)</span>th observation in the <span class="math inline">\(j\)</span>th group. The index of the model intercept <span class="math inline">\(b_{0(j)}\)</span> tells us a) that it is the intercept (parameter <span class="math inline">\(b_0\)</span>)and b) that it varies between the <span class="math inline">\(j\)</span> groups (<span class="math inline">\(j\)</span> in parentheses). We can partition this effect into its fixed component <span class="math inline">\(c_{0(0)}\)</span>, its index telling us that it no longer varies between groups (thus the 0 in parentheses), and a random component <span class="math inline">\(u_{0(j)}\)</span>. The index of this random component tells us that is belongs to the intercept and varies between the <span class="math inline">\(j\)</span> groups.</p>
<p>The name of the next parameter <span class="math inline">\(b_{1(0)}\)</span> reveals that this is regression weight of the first predictor (<span class="math inline">\(b_1\)</span>) and that it does not vary between groups (indicated by the zero in parentheses). We can further see that <span class="math inline">\(b_{1(0)}\)</span> is is a level-1 fixed effect because there is a value of the accompanying predictor <span class="math inline">\(X_{1(ij)}\)</span> for each of the <span class="math inline">\(i\)</span> observations within each of the <span class="math inline">\(j\)</span> groups (the <span class="math inline">\(ij\)</span> in parentheses tells us that <span class="math inline">\(X_1\)</span> varies at both levels).</p>
<p>Below is a visualisation of what a random intercept model with a single level-1 predictor could look like.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference9_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In the figure above, the bold black line represents the fixed part of the model. The intercept of this regression line is <span class="math inline">\(c_{0(0)}\)</span>, and its slope is <span class="math inline">\(b_{1_(0)}\)</span>. We can also see that the model has random intercepts for each team. This means that the regression line is shifted upward or downwards depending on which team we look at. Since the slope for the predictor <em>job demands</em> does not vary at level 2, it is equal for all teams as indicated by the regression lines running parallel. What this means is that while members of different teams seem to report different overall levels of stress, the increase in stress as job demands increase is equal for members of all teams.</p>
</section>
<section id="multi-level-models-with-random-intercepts-and-slopes" class="level3">
<h3 class="anchored" data-anchor-id="multi-level-models-with-random-intercepts-and-slopes">Multi-level models with random intercepts and slopes</h3>
<p>When we run multi-level models, we are not restricted to modelling random intercepts. We can also treat the slopes of our predictors as random effects, given that the respective predictor is not measured at the highest level. Let’s consider a model with a single level-1 predictor that contains random intercepts as well as random slopes for that predictor. Here is what the model looks like:</p>
<p><span class="math display">\[Y_{(ij)} = b_{0(j)} + b_{1(j)}X_{1(ij)} + \epsilon_{(ij)}\]</span> Here:</p>
<p><span class="math display">\[b_{0(j)} = c_{0(0)} + u_{0(j)}\]</span> And:</p>
<p><span class="math display">\[b_{1(j)} = c_{1(0)} + u_{1(j)}\]</span> As always, we assume that the random effects follow a normal distribution with mean zero. We can rewrite the model as follows:</p>
<p><span class="math display">\[Y_{(ij)} = c_{0(0)} + u_{0(j)} + c_{1(0)}X_{1(ij)} + u_{1(j)}X_{1(ij)} + \epsilon_{(ij)}\]</span> We already know what <span class="math inline">\(Y_{(ij)}\)</span>, <span class="math inline">\(c_{0(0)}\)</span>, <span class="math inline">\(u_{0(j)}\)</span>, and <span class="math inline">\(\epsilon_{(ij)}\)</span> denote. That leaves the two parameters related to the level-1 predictor <span class="math inline">\(X_1\)</span>. Here, <span class="math inline">\(c_{1(0)}\)</span> is the fixed effect of <span class="math inline">\(X_1\)</span>, which we can interpret as the average slope. The corresponding random effect, <span class="math inline">\(u_{1(j)}\)</span> indicates how the slopes differ from the fixed slope for <span class="math inline">\(j\)</span> groups. As with all random effects, we compute the deviations of the group slopes for the fixed slope, but we estimate <span class="math inline">\(u_{1(j)}\)</span> as a single parameter via the variance of the group slopes. Below is a visualisation of a random slope model.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="inference9_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>From the figure above, we can see that while job demands are positively associated with stress for people in all teams, the strength of this association is subject to some variation, meaning that the slope is steeper for some members of some teams than others.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>